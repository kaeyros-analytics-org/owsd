<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 11 Data preparation | OWSD WORKSHOP</title>
<meta name="author" content="Thierry Monthe">
<meta name="generator" content="bookdown 0.39 with bs4_book()">
<meta property="og:title" content="Chapter 11 Data preparation | OWSD WORKSHOP">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 11 Data preparation | OWSD WORKSHOP">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
<meta name="description" content="Data preparation is a crucial step in the machine learning pipeline that involves cleaning, transforming, and pre-processing raw data to make it suitable for training and evaluation. This process...">
<meta property="og:description" content="Data preparation is a crucial step in the machine learning pipeline that involves cleaning, transforming, and pre-processing raw data to make it suitable for training and evaluation. This process...">
<meta name="twitter:description" content="Data preparation is a crucial step in the machine learning pipeline that involves cleaning, transforming, and pre-processing raw data to make it suitable for training and evaluation. This process...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">OWSD WORKSHOP</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Welcome adress</a></li>
<li><a class="" href="introduction-to-r-and-rstudio.html"><span class="header-section-number">2</span> Introduction to R and RStudio</a></li>
<li><a class="" href="basics-of-the-r-language.html"><span class="header-section-number">3</span> Basics of the R language</a></li>
<li><a class="" href="functions-and-packages.html"><span class="header-section-number">4</span> Functions and packages</a></li>
<li><a class="" href="data-manipulation.html"><span class="header-section-number">5</span> Data manipulation</a></li>
<li><a class="" href="data-cleaning.html"><span class="header-section-number">6</span> Data cleaning</a></li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">7</span> Descriptive statistics</a></li>
<li><a class="" href="inferential-statistics.html"><span class="header-section-number">8</span> Inferential statistics</a></li>
<li><a class="" href="visualization.html"><span class="header-section-number">9</span> Visualization</a></li>
<li><a class="" href="introduction-to-machine-learning-and-machine-learning-techniques.html"><span class="header-section-number">10</span> Introduction to Machine Learning and Machine Learning techniques</a></li>
<li><a class="active" href="data-preparation.html"><span class="header-section-number">11</span> Data preparation</a></li>
<li><a class="" href="model-training-and-hyperparameter-tuning.html"><span class="header-section-number">12</span> Model training and hyperparameter tuning</a></li>
<li><a class="" href="model-deployment.html"><span class="header-section-number">13</span> Model deployment</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/rstudio/bookdown-demo">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="data-preparation" class="section level1" number="11">
<h1>
<span class="header-section-number">11</span> Data preparation<a class="anchor" aria-label="anchor" href="#data-preparation"><i class="fas fa-link"></i></a>
</h1>
<p>Data preparation is a crucial step in the machine learning pipeline that involves cleaning, transforming, and pre-processing raw data to make it suitable for training and evaluation. This process ensures that the data is in a format that machine learning algorithms can effectively learn from, ultimately improving the performance and generalization ability of the models. By carefully preparing the data before feeding it into machine learning algorithms, practitioners can mitigate potential issues such as overfitting, improve model accuracy, and facilitate meaningful insights from the data.</p>
<div id="data-cleaning-1" class="section level2" number="11.1">
<h2>
<span class="header-section-number">11.1</span> Data cleaning<br><a class="anchor" aria-label="anchor" href="#data-cleaning-1"><i class="fas fa-link"></i></a>
</h2>
<p>Data cleaning is an essential pre-processing step in machine learning that focuses on identifying and rectifying errors, inconsistencies, and inaccuracies in raw data. This process involves tasks such as handling missing values, removing duplicates, correcting data format inconsistencies, and dealing with outliers. Data cleaning ensures that the dataset is of high quality and integrity, which is crucial for building accurate and reliable machine learning models. By thoroughly cleaning the data, practitioners can enhance the quality of their analyses, improve model performance, and foster more meaningful insights from the data.</p>
</div>
<div id="feature-scaling" class="section level2" number="11.2">
<h2>
<span class="header-section-number">11.2</span> Feature scaling<br><a class="anchor" aria-label="anchor" href="#feature-scaling"><i class="fas fa-link"></i></a>
</h2>
<p>Feature scaling, is a technique used to transform numerical features in a dataset into a common scale. The goal is to bring the features to a similar magnitude, making them comparable and preventing any particular feature from dominating the learning algorithm due to its larger scale. Feature scaling is an essential preprocessing step in machine learning.
The most common methods for feature scaling are:</p>
<ul>
<li><p>Standardization: This method transforms the data to have zero mean and unit variance. It subtracts the mean and divides by the standard deviation of each feature. Standardization preserves the shape of the original distribution and is useful when the data does not have a normal distribution.</p></li>
<li><p>Normalization: Normalization scales the data to a fixed range, typically between 0 and 1. It is achieved by subtracting the minimum value and dividing by the range (maximum value minus minimum value) of each feature. Normalization is suitable for data that has a bounded range and follows a uniform distribution.</p></li>
</ul>
</div>
<div id="feature-creation" class="section level2" number="11.3">
<h2>
<span class="header-section-number">11.3</span> Feature creation<br><a class="anchor" aria-label="anchor" href="#feature-creation"><i class="fas fa-link"></i></a>
</h2>
<p>Feature creation, also known as feature engineering, is a critical aspect of machine learning where new features are derived or constructed from existing ones to enhance model performance and capture more complex relationships in the data. This process involves transforming raw input data into a more informative representation that better captures the underlying patterns and structures. Feature creation techniques may include mathematical transformations like log transforms, creating interaction terms between existing features, binning numerical features into categorical ones or encoding categorical variables. Effective feature creation can significantly impact the predictive power of machine learning models, enabling them to better generalize to unseen data and achieve higher levels of accuracy and robustness.</p>
</div>
<div id="feature-encoding" class="section level2" number="11.4">
<h2>
<span class="header-section-number">11.4</span> Feature encoding<br><a class="anchor" aria-label="anchor" href="#feature-encoding"><i class="fas fa-link"></i></a>
</h2>
<p>Feature encoding is a crucial step in machine learning where categorical variables are converted into numerical representations that algorithms can understand. Since many machine learning algorithms require numerical input, feature encoding transforms categorical data into a format that preserves the information contained in the original variables. 
Common techniques for feature encoding include one-hot encoding(it creates new (binary) columns, indicating the presence of each possible value from the original data), label encoding which assigns a unique numerical value to each category or ordinal encoding to ensure that ordinal nature of the variables is sustained.</p>
</div>
<div id="data-reduction" class="section level2" number="11.5">
<h2>
<span class="header-section-number">11.5</span> Data reduction<br><a class="anchor" aria-label="anchor" href="#data-reduction"><i class="fas fa-link"></i></a>
</h2>
<p>In machine learning, dimensionality reduction tackles the challenge of high-dimensional data. Imagine a vast landscape with many features representing different directions. Dimensionality reduction techniques condense the data into a lower-dimensional space while preserving the most important information. This not only simplifies analysis and visualization but also improves the performance of machine learning algorithms by reducing computational costs and the risk of overfitting. Dimensionnality techniques include feature selection and feature extraction.</p>
<ol style="list-style-type: decimal">
<li>Feature selection</li>
</ol>
<ul>
<li>Correlation analysis</li>
<li>Recursive Feature Elimination</li>
<li>Statistical tests</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Feature extraction</li>
</ol>
<ul>
<li>Principal Component Analysis (PCA)</li>
<li>Linear Discriminant Analysis (LDA)</li>
</ul>
</div>
<div id="handling-imbalanced-dataset" class="section level2" number="11.6">
<h2>
<span class="header-section-number">11.6</span> Handling imbalanced dataset<a class="anchor" aria-label="anchor" href="#handling-imbalanced-dataset"><i class="fas fa-link"></i></a>
</h2>
<p>Imbalanced datasets occur when one class significantly outnumbers the other(s), leading to biased model training and poor generalization performance.
We can handle imbalanced dataset by applying undersampling, oversampling or the method SMOTE.</p>
<ol style="list-style-type: decimal">
<li><p>undersampling:<br>
The process of undersampling counts the number of minority samples in the dataset, then randomly selects the same number from the majority sample.</p></li>
<li><p>oversampling:<br>
This method repeatedly duplicates randomly selected minority classes until there are an equal number of majority and minority samples.</p></li>
<li><p>SMOTE(Synthetic Minority Oversampling Technique):<br>
A very simple explanation is that it randomly selects a minority data point and looks at its nearest k minority class neighbours. It then randomly selects one of these neighbours, draws a line between them and creates a new data point randomly along that line. This will be repeated until the minority class has reached a predetermined ratio to the majority class.</p></li>
</ol>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="introduction-to-machine-learning-and-machine-learning-techniques.html"><span class="header-section-number">10</span> Introduction to Machine Learning and Machine Learning techniques</a></div>
<div class="next"><a href="model-training-and-hyperparameter-tuning.html"><span class="header-section-number">12</span> Model training and hyperparameter tuning</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#data-preparation"><span class="header-section-number">11</span> Data preparation</a></li>
<li><a class="nav-link" href="#data-cleaning-1"><span class="header-section-number">11.1</span> Data cleaning</a></li>
<li><a class="nav-link" href="#feature-scaling"><span class="header-section-number">11.2</span> Feature scaling</a></li>
<li><a class="nav-link" href="#feature-creation"><span class="header-section-number">11.3</span> Feature creation</a></li>
<li><a class="nav-link" href="#feature-encoding"><span class="header-section-number">11.4</span> Feature encoding</a></li>
<li><a class="nav-link" href="#data-reduction"><span class="header-section-number">11.5</span> Data reduction</a></li>
<li><a class="nav-link" href="#handling-imbalanced-dataset"><span class="header-section-number">11.6</span> Handling imbalanced dataset</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/rstudio/bookdown-demo/blob/master/10-data_preparation.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/rstudio/bookdown-demo/edit/master/10-data_preparation.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>OWSD WORKSHOP</strong>" was written by Thierry Monthe. It was last built on 2024-05-14.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>
</body>
</html>
